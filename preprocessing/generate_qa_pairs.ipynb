{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (1.20.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: sniffio in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/michaelpeng/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ['OPENAI_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract questions and answers from the generated question/answer pairs\n",
    "def parse_qa_string(qa_string):\n",
    "    qa_list = []\n",
    "    lines = qa_string.strip().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        parts = line.split('question: ')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        number_question, answer = parts[1].split('answer: ')\n",
    "        qa_list.append((number_question.strip(), answer.strip()))\n",
    "\n",
    "    return qa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_pairs(article_text, client):\n",
    "    \"\"\"\n",
    "    Takes in a text excerpt from a Wikipedia article and generates a list of question/answer pairs using GPT-3.5.\n",
    "    \n",
    "    Parameters:\n",
    "    - article_text (str): The excerpt of the Wikipedia article.\n",
    "    - client (openai.ApiClient): An instance of the OpenAI API client.\n",
    "    \n",
    "    Returns:\n",
    "    - str: A numbered list of question/answer pairs formatted as specified.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = (\n",
    "        \"I want to generate a list of 10 questions/answers from this wikipedia excerpt:\\n\"\n",
    "        + article_text +\n",
    "        \"\\nAn example of this might be question: 'When was George Washington born', answer: 'George Washington was born in 1732'.\\n\"\n",
    "        \"Please format your response as a numbered list of the form\\n\"\n",
    "        \"1. question: <generated question>, answer: <generated answer>\\n\"\n",
    "        \"2. question: <generated question>, answer: <generated answer>\\n\"\n",
    "        \"etc...\\n\"\n",
    "        \"where the question and answer are on the same line. Please only return the list as your response with no other text surrounding it.\\n\"\n",
    "        \"Keep in mind two points while generating these questions/answers:\\n\"\n",
    "        \"1) The questions should be answerable even without the given text (i.e. the question should not require something that was defined in the text to answer it).\\n\"\n",
    "        \"2) The answers should either be a single word or a short phrase.\\n\"\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are an AI. Please answer the following questions as if you were an expert on the subject. Please make sure that each question/answer pair\\\n",
    "                        is on the same line anad that the response has no other text surrounding it.\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0.5,\n",
    "                max_tokens=1000,\n",
    "                n=1,\n",
    "            )\n",
    "            qa_text = completion.choices[0].message.content\n",
    "            qa_list = parse_qa_string(qa_text)\n",
    "            return qa_list\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint qa_map\n",
    "if os.path.exists('qa_map.json'):\n",
    "    qa_map = load_json('qa_map.json')\n",
    "else:\n",
    "    qa_map = {}\n",
    "\n",
    "# Load articles\n",
    "post_2024_articles = load_json('../datasets/post_2024_articles.json')\n",
    "pre_2021_articles = load_json('../datasets/pre_2021_articles.json')\n",
    "\n",
    "# Generate question/answer pairs for each article\n",
    "for article_title, article_text in post_2024_articles.items():\n",
    "    if article_title in qa_map:\n",
    "        continue\n",
    "    qa_list = generate_qa_pairs(article_text, client)\n",
    "    qa_map[article_title] = qa_list\n",
    "    if len(qa_map) % 100 == 0:\n",
    "        print(len(qa_map))\n",
    "\n",
    "for article_title, article_text in pre_2021_articles.items():\n",
    "    if article_title in qa_map:\n",
    "        continue\n",
    "    qa_list = generate_qa_pairs(article_text, client)\n",
    "    qa_map[article_title] = qa_list\n",
    "    if len(qa_map) % 100 == 0:\n",
    "        print(len(qa_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(qa_map, 'datasets/qa_map.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
